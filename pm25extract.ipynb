{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b24e7a26-5d8b-4bd6-a946-4c208ad8f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5964a2a1-3ed6-41a5-817a-907dda3d571c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of      Grid_Cell          pm_x          pm_y     pm_lat      pm_lon   ID  \\\n",
      "0        15380 -1.545579e+06 -8.821908e+05  31.337204 -110.936718    1   \n",
      "1        17341 -1.412537e+06 -9.079196e+05  31.349200 -109.539683    2   \n",
      "2        21429 -1.137201e+06 -8.923216e+05  31.787885 -106.683324    3   \n",
      "3        21607 -1.125669e+06 -8.930981e+05  31.796218 -106.584434    4   \n",
      "4        13060 -1.698603e+06 -7.817011e+05  31.950000 -112.801000    5   \n",
      "..         ...           ...           ...        ...         ...  ...   \n",
      "475      16611 -1.424518e+06  1.034871e+06  48.510300 -113.996810  476   \n",
      "476       7267 -2.042921e+06  1.208466e+06  48.520590 -122.614280  477   \n",
      "477      12319 -1.708344e+06  1.104896e+06  48.544722 -117.903611  478   \n",
      "478       9080 -1.924266e+06  1.192342e+06  48.731420 -121.065815  479   \n",
      "479       7632 -2.017071e+06  1.221384e+06  48.762780 -122.440280  480   \n",
      "\n",
      "     Unnamed: 6  \n",
      "0           NaN  \n",
      "1           NaN  \n",
      "2           NaN  \n",
      "3           NaN  \n",
      "4           NaN  \n",
      "..          ...  \n",
      "475         NaN  \n",
      "476         NaN  \n",
      "477         NaN  \n",
      "478         NaN  \n",
      "479         NaN  \n",
      "\n",
      "[480 rows x 7 columns]>\n"
     ]
    }
   ],
   "source": [
    "state_codes = [\n",
    "    53, # Washington\n",
    "    41, # Oregon\n",
    "    6,  # California\n",
    "    32, # Nevada\n",
    "    16, # Idaho\n",
    "    56, # Wyoming\n",
    "    30, # Montana\n",
    "    35, # New Mexico\n",
    "    4,  # Arizona\n",
    "    8,  # Colorado\n",
    "    49  # Utah\n",
    "]\n",
    "mon_loc = pd.read_csv('PM_new_coord.csv', dtype={'Grid_Cell':'Int64', 'ID':'Int64'})\n",
    "print(mon_loc.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c217bb8a-9612-4c98-a330-112c6bbf8c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\Daily\\daily_88101_2013.csv\n",
      ".\\Daily\\daily_88101_2014.csv\n",
      ".\\Daily\\daily_88502_2013.csv\n",
      ".\\Daily\\daily_88502_2014.csv\n",
      ".\\Hourly\\hourly_88101_2013.csv\n",
      ".\\Hourly\\hourly_88101_2014.csv\n",
      ".\\Hourly\\hourly_88502_2013.csv\n",
      ".\\Hourly\\hourly_88502_2014.csv\n"
     ]
    }
   ],
   "source": [
    "first = True\n",
    "pm_df = None\n",
    "for fn in glob.glob('.\\Daily\\*.csv'):\n",
    "    print(fn)\n",
    "    df = pd.read_csv(fn, usecols=['State Code', 'County Code', 'Site Num', 'Date Local', 'Latitude', 'Longitude', 'Arithmetic Mean', 'Sample Duration'])\n",
    "    df = df[df['State Code'].isin(state_codes)]\n",
    "    \n",
    "    if first:\n",
    "        pm_df = df\n",
    "        first = False\n",
    "    else:\n",
    "        pm_df = pm_df.append(df)\n",
    "        \n",
    "for fn in glob.glob('.\\Hourly\\*.csv'):\n",
    "    print(fn)\n",
    "    df = pd.read_csv(fn, usecols=['State Code', 'Date Local', 'Latitude', 'Longitude', 'Sample Measurement', 'Method Name', 'Time Local'])\n",
    "    df = df[df['State Code'].isin(state_codes)]\n",
    "    \n",
    "    pm_df = pm_df.append(df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b1757bc-5f69-4612-81c8-44190726c90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                Latitude   Longitude\n",
      "Latitude  Longitude                                \n",
      "31.337204 -110.936718 15790   31.337204 -110.936718\n",
      "31.349200 -109.539683 7963    31.349200 -109.539683\n",
      "31.787885 -106.683324 165512  31.787885 -106.683324\n",
      "31.796218 -106.584434 164797  31.796218 -106.584434\n",
      "31.950000 -112.801000 8894    31.950000 -112.801000\n",
      "...                                 ...         ...\n",
      "48.510300 -113.996810 150908  48.510300 -113.996810\n",
      "48.520590 -122.614280 301385  48.520590 -122.614280\n",
      "48.544722 -117.903611 329631  48.544722 -117.903611\n",
      "48.731420 -121.065815 331764  48.731420 -121.065815\n",
      "48.762780 -122.440280 304898  48.762780 -122.440280\n",
      "\n",
      "[480 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "def r(g):\n",
    "    return g[['Latitude', 'Longitude']].loc[[g.index[0]]]\n",
    "\n",
    "gs = pm_df.groupby(['Latitude', 'Longitude'])\n",
    "locs = gs.apply(r)\n",
    "\n",
    "print(locs.head)\n",
    "locs.to_csv('mon_loc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d372c0ed-48ca-4c8c-b8b3-f709eca8e128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\Daily\\daily_88101_2013.csv\n",
      ".\\Daily\\daily_88101_2014.csv\n",
      ".\\Daily\\daily_88502_2013.csv\n",
      ".\\Daily\\daily_88502_2014.csv\n",
      "(471811, 14)\n",
      "<bound method NDFrame.head of         gridID          pm_x          pm_y     pm_lat      pm_lon  monID  \\\n",
      "0        15380 -1.545579e+06 -8.821908e+05  31.337204 -110.936718      1   \n",
      "1        15380 -1.545579e+06 -8.821908e+05  31.337204 -110.936718      1   \n",
      "2        15380 -1.545579e+06 -8.821908e+05  31.337204 -110.936718      1   \n",
      "3        15380 -1.545579e+06 -8.821908e+05  31.337204 -110.936718      1   \n",
      "4        15380 -1.545579e+06 -8.821908e+05  31.337204 -110.936718      1   \n",
      "...        ...           ...           ...        ...         ...    ...   \n",
      "114218    9080 -1.924266e+06  1.192342e+06  48.731420 -121.065815    479   \n",
      "114219    9080 -1.924266e+06  1.192342e+06  48.731420 -121.065815    479   \n",
      "114220    9080 -1.924266e+06  1.192342e+06  48.731420 -121.065815    479   \n",
      "114221    9080 -1.924266e+06  1.192342e+06  48.731420 -121.065815    479   \n",
      "114222    9080 -1.924266e+06  1.192342e+06  48.731420 -121.065815    479   \n",
      "\n",
      "        Unnamed: 6  State Code  Parameter Code   Latitude   Longitude  \\\n",
      "0              NaN           4           88101  31.337204 -110.936718   \n",
      "1              NaN           4           88101  31.337204 -110.936718   \n",
      "2              NaN           4           88101  31.337204 -110.936718   \n",
      "3              NaN           4           88101  31.337204 -110.936718   \n",
      "4              NaN           4           88101  31.337204 -110.936718   \n",
      "...            ...         ...             ...        ...         ...   \n",
      "114218         NaN          53           88502  48.731420 -121.065815   \n",
      "114219         NaN          53           88502  48.731420 -121.065815   \n",
      "114220         NaN          53           88502  48.731420 -121.065815   \n",
      "114221         NaN          53           88502  48.731420 -121.065815   \n",
      "114222         NaN          53           88502  48.731420 -121.065815   \n",
      "\n",
      "       Sample Duration        date  pm25  \n",
      "0              24 HOUR  2013-01-04  16.3  \n",
      "1              24 HOUR  2013-01-10  18.4  \n",
      "2              24 HOUR  2013-01-16  17.7  \n",
      "3              24 HOUR  2013-01-22  18.9  \n",
      "4              24 HOUR  2013-01-31  13.4  \n",
      "...                ...         ...   ...  \n",
      "114218         24 HOUR  2014-12-13   0.4  \n",
      "114219         24 HOUR  2014-12-16   0.9  \n",
      "114220         24 HOUR  2014-12-19   0.0  \n",
      "114221         24 HOUR  2014-12-22   2.9  \n",
      "114222         24 HOUR  2014-12-31   0.3  \n",
      "\n",
      "[471811 rows x 14 columns]>\n",
      "<IntegerArray>\n",
      "[  1,   2,  10,  11,  12,  14,  15,  16,  17,  18,\n",
      " ...\n",
      " 470, 472, 473, 474, 475, 476, 478, 479, 215, 356]\n",
      "Length: 476, dtype: Int64\n",
      "['24 HOUR' '1 HOUR' '24-HR BLK AVG']\n"
     ]
    }
   ],
   "source": [
    "# parse daily data\n",
    "first = True\n",
    "pm_df = None\n",
    "for fn in glob.glob('.\\Daily\\*.csv'):\n",
    "    print(fn)\n",
    "    df = pd.read_csv(fn, usecols=['State Code', 'Date Local', 'Latitude', 'Longitude', 'Arithmetic Mean', 'Sample Duration', 'Parameter Code'])\n",
    "    df = df[df['State Code'].isin(state_codes)]\n",
    "    df = pd.merge(mon_loc, df, how='inner', left_on=['pm_lat', 'pm_lon'], right_on=['Latitude', 'Longitude'])\n",
    "    \n",
    "    df.rename(columns={'Grid_Cell':'gridID', 'ID':'monID', 'Arithmetic Mean':'pm25', 'Date Local':'date'}, inplace=True)\n",
    "    \n",
    "    if first:\n",
    "        pm_df = df\n",
    "        first = False\n",
    "    else:\n",
    "        pm_df = pm_df.append(df)\n",
    "        \n",
    "\n",
    "\n",
    "print(pm_df.shape)\n",
    "print(pm_df.head)\n",
    "print(pd.unique(pm_df['monID']))\n",
    "print(pd.unique(pm_df['Sample Duration']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecb5e5cd-21d5-4f36-af7b-c7d2f6b1a8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225816\n",
      "<bound method NDFrame.head of               date  monID  level_2  gridID          pm_x          pm_y  \\\n",
      "0       2013-01-01      2        0   17341 -1.412537e+06 -9.079196e+05   \n",
      "1       2013-01-01      3      476   21429 -1.137201e+06 -8.923216e+05   \n",
      "2       2013-01-01      4     1201   21607 -1.125669e+06 -8.930981e+05   \n",
      "3       2013-01-01      5     1555   13060 -1.698603e+06 -7.817011e+05   \n",
      "4       2013-01-01      6     2024   21609 -1.124457e+06 -8.685132e+05   \n",
      "...            ...    ...      ...     ...           ...           ...   \n",
      "225811  2014-12-31    475   113293   26887 -7.307322e+05  9.212361e+05   \n",
      "225812  2014-12-31    476   113413   16611 -1.424518e+06  1.034871e+06   \n",
      "225813  2014-12-31    477   121540    7267 -2.042921e+06  1.208466e+06   \n",
      "225814  2014-12-31    479   114222    9080 -1.924266e+06  1.192342e+06   \n",
      "225815  2014-12-31    480   122204    7632 -2.017071e+06  1.221384e+06   \n",
      "\n",
      "           pm_lat      pm_lon  Unnamed: 6  State Code  Parameter Code  \\\n",
      "0       31.349200 -109.539683         NaN           4           88502   \n",
      "1       31.787885 -106.683324         NaN          35           88502   \n",
      "2       31.796218 -106.584434         NaN          35           88502   \n",
      "3       31.950000 -112.801000         NaN           4           88502   \n",
      "4       32.003712 -106.599715         NaN          35           88502   \n",
      "...           ...         ...         ...         ...             ...   \n",
      "225811  48.487054 -104.476346         NaN          30           88502   \n",
      "225812  48.510300 -113.996810         NaN          30           88502   \n",
      "225813  48.520590 -122.614280         NaN          53           88101   \n",
      "225814  48.731420 -121.065815         NaN          53           88502   \n",
      "225815  48.762780 -122.440280         NaN          53           88101   \n",
      "\n",
      "         Latitude   Longitude Sample Duration  pm25  priority  \n",
      "0       31.349200 -109.539683         24 HOUR   8.3         3  \n",
      "1       31.787885 -106.683324   24-HR BLK AVG   0.5         2  \n",
      "2       31.796218 -106.584434   24-HR BLK AVG   1.5         2  \n",
      "3       31.950000 -112.801000         24 HOUR   1.0         3  \n",
      "4       32.003712 -106.599715   24-HR BLK AVG   5.4         2  \n",
      "...           ...         ...             ...   ...       ...  \n",
      "225811  48.487054 -104.476346         24 HOUR   1.1         3  \n",
      "225812  48.510300 -113.996810         24 HOUR   3.3         3  \n",
      "225813  48.520590 -122.614280   24-HR BLK AVG  13.0         5  \n",
      "225814  48.731420 -121.065815         24 HOUR   0.3         3  \n",
      "225815  48.762780 -122.440280   24-HR BLK AVG  16.8         5  \n",
      "\n",
      "[225816 rows x 16 columns]>\n",
      "24-HR BLK AVG    165752\n",
      "24 HOUR           57355\n",
      "1 HOUR             2709\n",
      "Name: Sample Duration, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def fn(group):\n",
    "    mode = group.loc[group['Parameter Code'] == 88101]\n",
    "    if len(mode) >= 1:\n",
    "        a = mode.loc[mode['Sample Duration'] == '24 HOUR']\n",
    "        if len(a) >= 1:\n",
    "            res = a.iloc[[0]].drop(columns=['date', 'monID']).copy()\n",
    "            res['priority'] = 6\n",
    "            return res\n",
    "        b = mode.loc[mode['Sample Duration'] == '24-HR BLK AVG']\n",
    "        if len(b) >= 1:\n",
    "            res = b.iloc[[0]].drop(columns=['date', 'monID']).copy()\n",
    "            res['priority'] = 5\n",
    "            return res\n",
    "        c = mode.loc[mode['Sample Duration'] == '1 HOUR']\n",
    "        if len(c) >= 1:\n",
    "            res = c.iloc[[0]].drop(columns=['date', 'monID']).copy()\n",
    "            res['priority'] = 4\n",
    "            return res\n",
    "    \n",
    "    mode = group.loc[group['Parameter Code'] == 88502]\n",
    "    a = mode.loc[mode['Sample Duration'] == '24 HOUR']\n",
    "    if len(a) >= 1:\n",
    "        res = a.iloc[[0]].drop(columns=['date', 'monID']).copy()\n",
    "        res['priority'] = 3\n",
    "        return res\n",
    "    b = mode.loc[mode['Sample Duration'] == '24-HR BLK AVG']\n",
    "    if len(b) >= 1:\n",
    "        res = b.iloc[[0]].drop(columns=['date', 'monID']).copy()\n",
    "        res['priority'] = 2\n",
    "        return res\n",
    "    c = mode.loc[mode['Sample Duration'] == '1 HOUR']\n",
    "    if len(c) >= 1:\n",
    "        res = c.iloc[[0]].drop(columns=['date', 'monID']).copy()\n",
    "        res['priority'] = 1\n",
    "        return res\n",
    "    \n",
    "\n",
    "pm_df_grouped = pm_df.groupby(['date', 'monID'])\n",
    "print(len(pm_df_grouped))\n",
    "pm_df = pm_df_grouped.apply(fn).reset_index()\n",
    "\n",
    "print(pm_df.head)\n",
    "print(pm_df['Sample Duration'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "534f9d56-b721-4961-bc0d-14352f52caca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\Hourly\\hourly_88101_2013.csv\n",
      ".\\Hourly\\hourly_88101_2014.csv\n",
      ".\\Hourly\\hourly_88502_2013.csv\n",
      ".\\Hourly\\hourly_88502_2014.csv\n",
      "<IntegerArray>\n",
      "[  2,   3,   4,   5,   6,   7,   8,   9,  10,  11,\n",
      " ...\n",
      " 360, 356, 171,  22, 378, 159,  29,  23,  31, 313]\n",
      "Length: 480, dtype: Int64\n",
      "(413904, 18)\n"
     ]
    }
   ],
   "source": [
    "def hourly_mean(g):\n",
    "    mean = g['Sample Measurement'].mean()\n",
    "    res = g.iloc[[0]].copy()\n",
    "    res['Sample Measurement'] = mean\n",
    "    if res['Parameter Code'].iloc[0] == 88101:\n",
    "        res['priority'] = 8\n",
    "    else:\n",
    "        res['priority'] = 7\n",
    "    return res.drop(columns=['Date Local', 'Latitude', 'Longitude'])\n",
    "\n",
    "# parse hourly data\n",
    "for fn in glob.glob('.\\Hourly\\*.csv'):\n",
    "    print(fn)\n",
    "    df = pd.read_csv(fn, usecols=['State Code', 'Date Local', 'Latitude', 'Longitude', 'Sample Measurement', 'Time Local', 'Parameter Code'])\n",
    "    df = df[df['State Code'].isin(state_codes)]\n",
    "    grouped = df.groupby(['Date Local', 'Latitude', 'Longitude'])\n",
    "    #df = grouped[['Sample Measurement']].mean().reset_index()\n",
    "    df = grouped.apply(hourly_mean).reset_index()\n",
    "    df = pd.merge(mon_loc, df, how='inner', left_on=['pm_lat', 'pm_lon'], right_on=['Latitude', 'Longitude'])\n",
    "    df.rename(columns={'Grid_Cell':'gridID', 'ID':'monID', 'Sample Measurement':'pm25', 'Date Local':'date'}, inplace=True)\n",
    "    \n",
    "    pm_df = pm_df.append(df)\n",
    "\n",
    "\n",
    "print(pd.unique(pm_df['monID']))\n",
    "print(pm_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d690b556-19bb-4eb2-b7c0-4a890cad3555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sizing(group):\n",
    "    l = len(group)\n",
    "    if l != 24:\n",
    "        return group.join(pd.Series([l]*l, name='size', index=group.index))\n",
    "    \n",
    "    \n",
    "grouped = pm_df.groupby(['date', 'monID'])\n",
    "sizes = grouped.apply(sizing)\n",
    "sizes = sizes.loc[sizes['size'] != 24]\n",
    "sizes.to_csv('hourly_anomaly.csv', columns=['date', 'monID', 'Time Local', 'Method Name', 'pm25', 'size'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b6aa626-f25b-489d-8195-cc8bf4e54337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(413904, 18)\n",
      "[  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
      "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
      " 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n",
      " 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n",
      " 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162\n",
      " 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180\n",
      " 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198\n",
      " 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216\n",
      " 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234\n",
      " 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252\n",
      " 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270\n",
      " 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288\n",
      " 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306\n",
      " 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324\n",
      " 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342\n",
      " 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360\n",
      " 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378\n",
      " 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396\n",
      " 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414\n",
      " 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432\n",
      " 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450\n",
      " 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468\n",
      " 469 470 471 472 473 474 475 476 477 478 479 480]\n",
      "480\n",
      "(227016, 18)\n"
     ]
    }
   ],
   "source": [
    "def take(g):\n",
    "    return g.loc[[g['priority'].idxmax()]].drop(columns=['monID', 'date'])\n",
    "\n",
    "print(pm_df.shape)\n",
    "\n",
    "pm_df_grouped = pm_df.groupby(['monID', 'date'])\n",
    "pm_df = pm_df_grouped.apply(take).drop(columns=['level_2']).reset_index()\n",
    "\n",
    "\n",
    "print(pd.unique(pm_df['monID']))\n",
    "print(len(pd.unique(pm_df['monID'])))\n",
    "print(pm_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a06bce1c-d4c6-40c1-bdb5-47342095abd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "[274 277]\n",
      "[201 202]\n",
      "[158 159]\n",
      "[188 189]\n",
      "[104 105]\n",
      "[319 320]\n",
      "[205 206]\n",
      "[331 332]\n",
      "[335 336]\n",
      "[312 313 314]\n",
      "[ 97  99 101]\n",
      "[114 115]\n",
      "[244 245]\n",
      "[378 380 381]\n",
      "[56 57 58]\n",
      "[213 214]\n",
      "[233 234]\n",
      "[340 341]\n",
      "[78 79]\n",
      "[424 426 427]\n",
      "[441 442 445 448 449]\n",
      "[31 32]\n",
      "[14 17]\n",
      "[66 67]\n",
      "[459 460]\n",
      "[20 22]\n",
      "[29 30]\n",
      "[23 24]\n",
      "[435 436]\n",
      "[422 423]\n",
      "[133 134]\n",
      "[368 369]\n",
      "[395 396]\n",
      "[399 401]\n",
      "[41 46]\n",
      "[36 37]\n",
      "[38 39]\n",
      "[10 12]\n",
      "[273 275]\n",
      "[107 108]\n",
      "[239 240 243 246]\n",
      "(206773, 19)\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 30, 32, 33, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 100, 101, 102, 103, 105, 106, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 206, 207, 208, 209, 210, 211, 212, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 240, 241, 242, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 276, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 314, 315, 316, 317, 318, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 332, 333, 334, 336, 337, 338, 339, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 370, 371, 372, 373, 374, 375, 376, 377, 379, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 396, 397, 398, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 423, 425, 426, 428, 429, 430, 431, 432, 433, 434, 436, 437, 438, 439, 440, 442, 443, 444, 446, 447, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480]\n"
     ]
    }
   ],
   "source": [
    "def r(g):\n",
    "    monIDs = pd.unique(g['monID'])\n",
    "    if len(monIDs) == 1:\n",
    "        return g.drop(columns=['gridID'])\n",
    "    print(monIDs)\n",
    "    mon_groups = g.groupby(['monID'])\n",
    "    max_datapoints = 0\n",
    "    highest_priority = 0\n",
    "    best = None\n",
    "    for _, group in mon_groups:\n",
    "        if len(group) > max_datapoints:\n",
    "            best = group\n",
    "            max_datapoints = len(group)\n",
    "            highest_priority = 0\n",
    "        elif len(group) == max_datapoints:\n",
    "            priority = group['priority'].mean()\n",
    "            if priority > highest_priority:\n",
    "                best = group\n",
    "                highest_priority = priority\n",
    "    \n",
    "    return best.drop(columns=['gridID'])\n",
    "    \n",
    "\n",
    "g = pm_df.groupby(['gridID'])\n",
    "print(len(g))\n",
    "pm_df_unique = g.apply(r).reset_index()\n",
    "print(pm_df_unique.shape)\n",
    "print(sorted(pd.unique(pm_df_unique['monID'])))\n",
    "pm_df_unique.to_csv('pm25.csv', columns=['date', 'gridID', 'monID', 'pm25', 'Parameter Code'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ca26c8f7-8ca8-4a08-8661-e865a3249f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           monID\n",
      "pm25            \n",
      "1     250.657596\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
